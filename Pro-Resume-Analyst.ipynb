{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T18:06:10.888000600Z",
     "start_time": "2026-01-02T18:06:10.813904700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "16c0ddd115061056",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T18:06:19.178844800Z",
     "start_time": "2026-01-02T18:06:10.890540800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from scripts import base_tools\n",
    "from langsmith.wrappers import wrap_gemini"
   ],
   "id": "ab947249526439a8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-02T18:06:25.389098500Z",
     "start_time": "2026-01-02T18:06:19.322053300Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "from langchain.tools import tool\n",
    "from typing import Dict, Any, List\n",
    "from docling.document_converter import DocumentConverter\n",
    "import json\n",
    "import re\n",
    "\n",
    "@tool\n",
    "def read_resume(file_path: str) -> str:\n",
    "    \"\"\"Read a resume from the specified file path and return its content using Docling.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path to the resume file to read (PDF, DOCX, etc.).\n",
    "    \"\"\"\n",
    "    print(f\"Reading resume from: {file_path}\")\n",
    "    try:\n",
    "        # Initialize Docling converter\n",
    "        converter = DocumentConverter()\n",
    "\n",
    "        # Convert the document\n",
    "        result = converter.convert(file_path)\n",
    "\n",
    "        # Extract text content\n",
    "        resume_text = result.document.export_to_markdown()\n",
    "\n",
    "        print(f\"Successfully read resume. Content length: {len(resume_text)} characters\")\n",
    "        return resume_text\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error reading resume: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "@tool\n",
    "def extract_information(resume_content: str) -> str:\n",
    "    \"\"\"Extract information such as name, contact, experience, skills, and education from resume content.\n",
    "\n",
    "    Args:\n",
    "        resume_content: The content of the resume to extract information from.\n",
    "    \"\"\"\n",
    "    print(\"Extracting information from resume\")\n",
    "\n",
    "    try:\n",
    "        extracted_data = {\n",
    "            \"name\": \"\",\n",
    "            \"contact\": {\"email\": \"\", \"phone\": \"\", \"linkedin\": \"\", \"location\": \"\"},\n",
    "            \"summary\": \"\",\n",
    "            \"experience\": [],\n",
    "            \"skills\": [],\n",
    "            \"education\": [],\n",
    "            \"certifications\": [],\n",
    "            \"languages\": []\n",
    "        }\n",
    "\n",
    "        lines = resume_content.split('\\n')\n",
    "\n",
    "        # Extract email\n",
    "        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "        emails = re.findall(email_pattern, resume_content)\n",
    "        if emails:\n",
    "            extracted_data[\"contact\"][\"email\"] = emails[0]\n",
    "\n",
    "        # Extract phone numbers\n",
    "        phone_pattern = r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]'\n",
    "        phones = re.findall(phone_pattern, resume_content)\n",
    "        if phones:\n",
    "            extracted_data[\"contact\"][\"phone\"] = phones[0].strip()\n",
    "\n",
    "        # Extract LinkedIn\n",
    "        linkedin_pattern = r'linkedin\\.com/in/[\\w-]+'\n",
    "        linkedin = re.findall(linkedin_pattern, resume_content.lower())\n",
    "        if linkedin:\n",
    "            extracted_data[\"contact\"][\"linkedin\"] = linkedin[0]\n",
    "\n",
    "        # Try to extract name (usually first non-empty line or largest text)\n",
    "        for line in lines[:5]:\n",
    "            line = line.strip()\n",
    "            if line and len(line) < 50 and not any(char.isdigit() for char in line):\n",
    "                if '@' not in line and 'http' not in line.lower():\n",
    "                    extracted_data[\"name\"] = line\n",
    "                    break\n",
    "\n",
    "        # Extract sections\n",
    "        current_section = \"\"\n",
    "        section_content = []\n",
    "\n",
    "        for line in lines:\n",
    "            line_lower = line.lower().strip()\n",
    "\n",
    "            # Identify sections\n",
    "            if any(keyword in line_lower for keyword in ['experience', 'work history', 'employment']):\n",
    "                if current_section == \"experience\" and section_content:\n",
    "                    extracted_data[\"experience\"].append('\\n'.join(section_content))\n",
    "                current_section = \"experience\"\n",
    "                section_content = []\n",
    "            elif any(keyword in line_lower for keyword in ['education', 'academic']):\n",
    "                if current_section == \"experience\" and section_content:\n",
    "                    extracted_data[\"experience\"].append('\\n'.join(section_content))\n",
    "                current_section = \"education\"\n",
    "                section_content = []\n",
    "            elif any(keyword in line_lower for keyword in ['skills', 'technical skills', 'competencies']):\n",
    "                if current_section and section_content:\n",
    "                    if current_section == \"experience\":\n",
    "                        extracted_data[\"experience\"].append('\\n'.join(section_content))\n",
    "                    elif current_section == \"education\":\n",
    "                        extracted_data[\"education\"].append('\\n'.join(section_content))\n",
    "                current_section = \"skills\"\n",
    "                section_content = []\n",
    "            elif any(keyword in line_lower for keyword in ['summary', 'profile', 'objective']):\n",
    "                current_section = \"summary\"\n",
    "                section_content = []\n",
    "            elif any(keyword in line_lower for keyword in ['certification', 'certificate']):\n",
    "                if current_section and section_content:\n",
    "                    if current_section == \"experience\":\n",
    "                        extracted_data[\"experience\"].append('\\n'.join(section_content))\n",
    "                    elif current_section == \"education\":\n",
    "                        extracted_data[\"education\"].append('\\n'.join(section_content))\n",
    "                current_section = \"certifications\"\n",
    "                section_content = []\n",
    "            elif any(keyword in line_lower for keyword in ['languages', 'language proficiency']):\n",
    "                current_section = \"languages\"\n",
    "                section_content = []\n",
    "            elif line.strip():\n",
    "                if current_section == \"summary\":\n",
    "                    extracted_data[\"summary\"] += \" \" + line.strip()\n",
    "                elif current_section == \"skills\":\n",
    "                    extracted_data[\"skills\"].append(line.strip())\n",
    "                elif current_section in [\"experience\", \"education\", \"certifications\", \"languages\"]:\n",
    "                    section_content.append(line.strip())\n",
    "\n",
    "        # Add remaining section content\n",
    "        if current_section == \"experience\" and section_content:\n",
    "            extracted_data[\"experience\"].append('\\n'.join(section_content))\n",
    "        elif current_section == \"education\" and section_content:\n",
    "            extracted_data[\"education\"].append('\\n'.join(section_content))\n",
    "        elif current_section == \"certifications\" and section_content:\n",
    "            extracted_data[\"certifications\"] = section_content\n",
    "        elif current_section == \"languages\" and section_content:\n",
    "            extracted_data[\"languages\"] = section_content\n",
    "\n",
    "        print(f\"Successfully extracted information. Name: {extracted_data['name']}\")\n",
    "        return json.dumps(extracted_data, indent=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error extracting information: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return json.dumps({\"error\": error_msg})\n",
    "\n",
    "@tool\n",
    "def generate_summary(extracted_data: str) -> str:\n",
    "    \"\"\"Generate a comprehensive summary report based on extracted data from a resume.\n",
    "\n",
    "    Args:\n",
    "        extracted_data: A JSON string containing extracted information from the resume.\n",
    "    \"\"\"\n",
    "    print(\"Generating summary report\")\n",
    "\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        data = json.loads(extracted_data)\n",
    "\n",
    "        # Build the summary report\n",
    "        summary_parts = []\n",
    "\n",
    "        # Header\n",
    "        summary_parts.append(\"=\" * 60)\n",
    "        summary_parts.append(\"RESUME ANALYSIS SUMMARY\")\n",
    "        summary_parts.append(\"=\" * 60)\n",
    "        summary_parts.append(\"\")\n",
    "\n",
    "        # Personal Information\n",
    "        summary_parts.append(\"üìã PERSONAL INFORMATION\")\n",
    "        summary_parts.append(\"-\" * 60)\n",
    "        if data.get(\"name\"):\n",
    "            summary_parts.append(f\"Name: {data['name']}\")\n",
    "\n",
    "        contact = data.get(\"contact\", {})\n",
    "        if contact.get(\"email\"):\n",
    "            summary_parts.append(f\"Email: {contact['email']}\")\n",
    "        if contact.get(\"phone\"):\n",
    "            summary_parts.append(f\"Phone: {contact['phone']}\")\n",
    "        if contact.get(\"linkedin\"):\n",
    "            summary_parts.append(f\"LinkedIn: {contact['linkedin']}\")\n",
    "        if contact.get(\"location\"):\n",
    "            summary_parts.append(f\"Location: {contact['location']}\")\n",
    "        summary_parts.append(\"\")\n",
    "\n",
    "        # Professional Summary\n",
    "        if data.get(\"summary\"):\n",
    "            summary_parts.append(\"üíº PROFESSIONAL SUMMARY\")\n",
    "            summary_parts.append(\"-\" * 60)\n",
    "            summary_parts.append(data[\"summary\"].strip())\n",
    "            summary_parts.append(\"\")\n",
    "\n",
    "        # Experience\n",
    "        if data.get(\"experience\"):\n",
    "            summary_parts.append(\"üè¢ WORK EXPERIENCE\")\n",
    "            summary_parts.append(\"-\" * 60)\n",
    "            for idx, exp in enumerate(data[\"experience\"], 1):\n",
    "                if exp.strip():\n",
    "                    summary_parts.append(f\"\\n{idx}. {exp}\")\n",
    "            summary_parts.append(\"\")\n",
    "\n",
    "        # Skills\n",
    "        if data.get(\"skills\"):\n",
    "            summary_parts.append(\"üõ†Ô∏è SKILLS\")\n",
    "            summary_parts.append(\"-\" * 60)\n",
    "            skills_list = [s for s in data[\"skills\"] if s.strip()]\n",
    "            if skills_list:\n",
    "                summary_parts.append(\", \".join(skills_list[:20]))  # Limit to first 20 skills\n",
    "            summary_parts.append(\"\")\n",
    "\n",
    "        # Education\n",
    "        if data.get(\"education\"):\n",
    "            summary_parts.append(\"üéì EDUCATION\")\n",
    "            summary_parts.append(\"-\" * 60)\n",
    "            for idx, edu in enumerate(data[\"education\"], 1):\n",
    "                if edu.strip():\n",
    "                    summary_parts.append(f\"{idx}. {edu}\")\n",
    "            summary_parts.append(\"\")\n",
    "\n",
    "        # Certifications\n",
    "        if data.get(\"certifications\"):\n",
    "            summary_parts.append(\"üìú CERTIFICATIONS\")\n",
    "            summary_parts.append(\"-\" * 60)\n",
    "            for cert in data[\"certifications\"]:\n",
    "                if cert.strip():\n",
    "                    summary_parts.append(f\"‚Ä¢ {cert}\")\n",
    "            summary_parts.append(\"\")\n",
    "\n",
    "        # Languages\n",
    "        if data.get(\"languages\"):\n",
    "            summary_parts.append(\"üåê LANGUAGES\")\n",
    "            summary_parts.append(\"-\" * 60)\n",
    "            for lang in data[\"languages\"]:\n",
    "                if lang.strip():\n",
    "                    summary_parts.append(f\"‚Ä¢ {lang}\")\n",
    "            summary_parts.append(\"\")\n",
    "\n",
    "        # Key Insights\n",
    "        summary_parts.append(\"üí° KEY INSIGHTS\")\n",
    "        summary_parts.append(\"-\" * 60)\n",
    "        insights = []\n",
    "\n",
    "        if data.get(\"experience\"):\n",
    "            exp_count = len([e for e in data[\"experience\"] if e.strip()])\n",
    "            insights.append(f\"‚Ä¢ {exp_count} work experience entries documented\")\n",
    "\n",
    "        if data.get(\"skills\"):\n",
    "            skill_count = len([s for s in data[\"skills\"] if s.strip()])\n",
    "            insights.append(f\"‚Ä¢ {skill_count} skills identified\")\n",
    "\n",
    "        if data.get(\"education\"):\n",
    "            edu_count = len([e for e in data[\"education\"] if e.strip()])\n",
    "            insights.append(f\"‚Ä¢ {edu_count} educational qualifications listed\")\n",
    "\n",
    "        if data.get(\"certifications\"):\n",
    "            cert_count = len([c for c in data[\"certifications\"] if c.strip()])\n",
    "            insights.append(f\"‚Ä¢ {cert_count} certifications obtained\")\n",
    "\n",
    "        summary_parts.extend(insights)\n",
    "        summary_parts.append(\"\")\n",
    "        summary_parts.append(\"=\" * 60)\n",
    "\n",
    "        summary = \"\\n\".join(summary_parts)\n",
    "        print(\"Summary report generated successfully\")\n",
    "        return summary\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        error_msg = f\"Error parsing extracted data: {str(e)}\\nReceived data: {extracted_data[:200]}...\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error generating summary: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "@tool\n",
    "def calculate_experience_years(extracted_data: str) -> str:\n",
    "    \"\"\"Calculate total years of experience from the extracted resume data.\n",
    "\n",
    "    Args:\n",
    "        extracted_data: A JSON string containing extracted information from the resume.\n",
    "    \"\"\"\n",
    "    print(\"Calculating years of experience\")\n",
    "\n",
    "    try:\n",
    "        data = json.loads(extracted_data)\n",
    "        experience_entries = data.get(\"experience\", [])\n",
    "\n",
    "        # Common year patterns\n",
    "        year_pattern = r'\\b(19|20)\\d{2}\\b'\n",
    "        duration_pattern = r'(\\d+)\\s*(year|yr|years|yrs)'\n",
    "\n",
    "        total_years = 0\n",
    "        year_ranges = []\n",
    "\n",
    "        for exp in experience_entries:\n",
    "            # Look for year ranges (e.g., \"2020 - 2023\" or \"2020-Present\")\n",
    "            years = re.findall(year_pattern, exp)\n",
    "            if len(years) >= 2:\n",
    "                start_year = int(years[0])\n",
    "                end_year = int(years[1]) if years[1] else 2026\n",
    "                duration = end_year - start_year\n",
    "                year_ranges.append((start_year, end_year, duration))\n",
    "                total_years += duration\n",
    "\n",
    "            # Look for explicit duration mentions\n",
    "            durations = re.findall(duration_pattern, exp.lower())\n",
    "            for duration, _ in durations:\n",
    "                total_years += int(duration)\n",
    "\n",
    "        result = {\n",
    "            \"total_years\": total_years,\n",
    "            \"year_ranges\": year_ranges,\n",
    "            \"experience_count\": len(experience_entries)\n",
    "        }\n",
    "\n",
    "        report = f\"Total Years of Experience: {total_years}\\n\"\n",
    "        report += f\"Number of Positions: {len(experience_entries)}\\n\"\n",
    "        if year_ranges:\n",
    "            report += \"\\nExperience Timeline:\\n\"\n",
    "            for start, end, duration in year_ranges:\n",
    "                end_str = \"Present\" if end == 2026 else str(end)\n",
    "                report += f\"  ‚Ä¢ {start} - {end_str} ({duration} years)\\n\"\n",
    "\n",
    "        print(f\"Calculated {total_years} years of experience\")\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error calculating experience: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "@tool\n",
    "def match_job_requirements(extracted_data: str, job_requirements: str) -> str:\n",
    "    \"\"\"Match resume skills and experience against job requirements.\n",
    "\n",
    "    Args:\n",
    "        extracted_data: A JSON string containing extracted information from the resume.\n",
    "        job_requirements: A string describing the job requirements to match against.\n",
    "    \"\"\"\n",
    "    print(\"Matching resume against job requirements\")\n",
    "\n",
    "    try:\n",
    "        data = json.loads(extracted_data)\n",
    "        resume_skills = [skill.lower().strip() for skill in data.get(\"skills\", []) if skill.strip()]\n",
    "\n",
    "        # Extract keywords from job requirements\n",
    "        job_req_lower = job_requirements.lower()\n",
    "        job_keywords = set()\n",
    "\n",
    "        # Common tech skills and keywords\n",
    "        common_skills = [\n",
    "            'python', 'java', 'javascript', 'typescript', 'react', 'angular', 'vue',\n",
    "            'node', 'django', 'flask', 'spring', 'sql', 'nosql', 'mongodb', 'postgresql',\n",
    "            'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'ci/cd', 'git', 'agile',\n",
    "            'scrum', 'machine learning', 'ai', 'data science', 'analytics', 'leadership',\n",
    "            'communication', 'project management', 'api', 'rest', 'microservices'\n",
    "        ]\n",
    "\n",
    "        for skill in common_skills:\n",
    "            if skill in job_req_lower:\n",
    "                job_keywords.add(skill)\n",
    "\n",
    "        # Match resume skills against job keywords\n",
    "        matched_skills = []\n",
    "        missing_skills = []\n",
    "\n",
    "        for keyword in job_keywords:\n",
    "            if any(keyword in resume_skill for resume_skill in resume_skills):\n",
    "                matched_skills.append(keyword)\n",
    "            else:\n",
    "                missing_skills.append(keyword)\n",
    "\n",
    "        # Calculate match percentage\n",
    "        total_keywords = len(job_keywords)\n",
    "        match_percentage = (len(matched_skills) / total_keywords * 100) if total_keywords > 0 else 0\n",
    "\n",
    "        # Build report\n",
    "        report_parts = []\n",
    "        report_parts.append(\"=\" * 60)\n",
    "        report_parts.append(\"JOB REQUIREMENTS MATCH ANALYSIS\")\n",
    "        report_parts.append(\"=\" * 60)\n",
    "        report_parts.append(\"\")\n",
    "        report_parts.append(f\"üìä Match Score: {match_percentage:.1f}%\")\n",
    "        report_parts.append(\"\")\n",
    "\n",
    "        if matched_skills:\n",
    "            report_parts.append(\"‚úÖ MATCHING SKILLS:\")\n",
    "            for skill in matched_skills:\n",
    "                report_parts.append(f\"  ‚Ä¢ {skill}\")\n",
    "            report_parts.append(\"\")\n",
    "\n",
    "        if missing_skills:\n",
    "            report_parts.append(\"‚ùå MISSING SKILLS:\")\n",
    "            for skill in missing_skills:\n",
    "                report_parts.append(f\"  ‚Ä¢ {skill}\")\n",
    "            report_parts.append(\"\")\n",
    "\n",
    "        report_parts.append(\"üí° RECOMMENDATIONS:\")\n",
    "        if match_percentage >= 70:\n",
    "            report_parts.append(\"  ‚Ä¢ Strong match! Consider applying for this position.\")\n",
    "        elif match_percentage >= 50:\n",
    "            report_parts.append(\"  ‚Ä¢ Good match. Consider highlighting relevant experience.\")\n",
    "        else:\n",
    "            report_parts.append(\"  ‚Ä¢ Consider acquiring missing skills or emphasizing transferable skills.\")\n",
    "\n",
    "        report_parts.append(\"=\" * 60)\n",
    "\n",
    "        report = \"\\n\".join(report_parts)\n",
    "        print(f\"Match analysis complete. Score: {match_percentage:.1f}%\")\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error matching job requirements: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "@tool\n",
    "def suggest_improvements(extracted_data: str) -> str:\n",
    "    \"\"\"Provide actionable suggestions to improve the resume.\n",
    "\n",
    "    Args:\n",
    "        extracted_data: A JSON string containing extracted information from the resume.\n",
    "    \"\"\"\n",
    "    print(\"Generating improvement suggestions\")\n",
    "\n",
    "    try:\n",
    "        data = json.loads(extracted_data)\n",
    "        suggestions = []\n",
    "\n",
    "        # Check name\n",
    "        if not data.get(\"name\"):\n",
    "            suggestions.append(\"‚ö†Ô∏è Name is missing or not clearly visible. Ensure your name is prominent at the top.\")\n",
    "\n",
    "        # Check contact information\n",
    "        contact = data.get(\"contact\", {})\n",
    "        if not contact.get(\"email\"):\n",
    "            suggestions.append(\"‚ö†Ô∏è Email address is missing. Add a professional email address.\")\n",
    "        if not contact.get(\"phone\"):\n",
    "            suggestions.append(\"üí° Consider adding a phone number for easy contact.\")\n",
    "        if not contact.get(\"linkedin\"):\n",
    "            suggestions.append(\"üí° Add your LinkedIn profile URL to strengthen your professional presence.\")\n",
    "\n",
    "        # Check summary\n",
    "        if not data.get(\"summary\"):\n",
    "            suggestions.append(\"‚ö†Ô∏è Professional summary is missing. Add a 2-3 sentence summary highlighting your expertise.\")\n",
    "        elif len(data.get(\"summary\", \"\")) < 100:\n",
    "            suggestions.append(\"üí° Your professional summary is brief. Expand it to better showcase your value proposition.\")\n",
    "\n",
    "        # Check experience\n",
    "        experience = data.get(\"experience\", [])\n",
    "        if not experience:\n",
    "            suggestions.append(\"‚ö†Ô∏è Work experience section is missing or not detected. This is a critical section.\")\n",
    "        elif len(experience) < 2:\n",
    "            suggestions.append(\"üí° Consider adding more detailed work experience entries with achievements and metrics.\")\n",
    "\n",
    "        # Check skills\n",
    "        skills = [s for s in data.get(\"skills\", []) if s.strip()]\n",
    "        if not skills:\n",
    "            suggestions.append(\"‚ö†Ô∏è Skills section is missing or not detected. Add a dedicated skills section.\")\n",
    "        elif len(skills) < 5:\n",
    "            suggestions.append(\"üí° Add more relevant skills to increase your visibility in applicant tracking systems.\")\n",
    "\n",
    "        # Check education\n",
    "        if not data.get(\"education\"):\n",
    "            suggestions.append(\"‚ö†Ô∏è Education section is missing or not detected. Include your educational background.\")\n",
    "\n",
    "        # Check certifications\n",
    "        if not data.get(\"certifications\"):\n",
    "            suggestions.append(\"üí° Consider adding relevant certifications to strengthen your credentials.\")\n",
    "\n",
    "        # General suggestions\n",
    "        suggestions.append(\"\")\n",
    "        suggestions.append(\"‚ú® GENERAL BEST PRACTICES:\")\n",
    "        suggestions.append(\"  ‚Ä¢ Use action verbs (Led, Developed, Implemented, Achieved)\")\n",
    "        suggestions.append(\"  ‚Ä¢ Include quantifiable achievements (e.g., 'Increased revenue by 30%')\")\n",
    "        suggestions.append(\"  ‚Ä¢ Keep formatting consistent throughout the document\")\n",
    "        suggestions.append(\"  ‚Ä¢ Tailor your resume for each job application\")\n",
    "        suggestions.append(\"  ‚Ä¢ Keep it concise (1-2 pages for most professionals)\")\n",
    "        suggestions.append(\"  ‚Ä¢ Use keywords from job descriptions to pass ATS systems\")\n",
    "\n",
    "        # Build report\n",
    "        report_parts = []\n",
    "        report_parts.append(\"=\" * 60)\n",
    "        report_parts.append(\"RESUME IMPROVEMENT SUGGESTIONS\")\n",
    "        report_parts.append(\"=\" * 60)\n",
    "        report_parts.append(\"\")\n",
    "        report_parts.extend(suggestions)\n",
    "        report_parts.append(\"\")\n",
    "        report_parts.append(\"=\" * 60)\n",
    "\n",
    "        report = \"\\n\".join(report_parts)\n",
    "        print(f\"Generated {len(suggestions)} improvement suggestions\")\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error generating suggestions: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "# System prompt for the Resume Analysis Agent\n",
    "# system_prompt = \"\"\"You are a professional resume analysis expert specializing in evaluating and improving resumes.\n",
    "# **Your Responsibilities:**\n",
    "# 1. Analyze and assess the overall quality and effectiveness of resumes.\n",
    "# 2. Provide insights on work experience, skills, and education.\n",
    "# 3. Offer constructive feedback and suggestions for enhancing resumes.\n",
    "# 4. Use available tools to extract and analyze key information.\n",
    "# **Analysis Framework:**\n",
    "# - Personal Information: Name, Contact, LinkedIn Profile\n",
    "# - Professional Summary: Key achievements and career goals\n",
    "# - Work Experience: Roles, responsibilities, and achievements\n",
    "# - Skills: Technical and soft skills relevant to the industry\n",
    "# - Education: Degrees, certifications, and relevant coursework\n",
    "# - Additional Sections: Awards, publications, languages\n",
    "# - Overall Format and Style: Clarity, conciseness, and professionalism\n",
    "# **Important Guidelines:**\n",
    "# - Only respond to questions related to resume analysis and improvement.\n",
    "# - For non-relevant questions, politely decline: \"I apologize, but I can only assist with resume analysis and improvement. Please ask me about resume-related queries.\"\n",
    "# - Always provide specific examples and metrics when giving feedback.\n",
    "# - Maintain a supportive and constructive tone.\n",
    "# Provide clear, actionable suggestions that help individuals enhance their resumes for potential employers.\"\"\"\n",
    "# Improved System Prompt for the Resume Analysis Agent\n",
    "system_prompt = \"\"\"You are a professional resume analysis expert specializing in evaluating and improving resumes across diverse industries.\n",
    "**Your Responsibilities:**\n",
    "1. Thoroughly analyze and assess the overall quality and effectiveness of resumes.\n",
    "2. Provide insights on work experience, skills, and education, tailored to specific industries.\n",
    "3. Offer constructive feedback and actionable suggestions for enhancing resumes, ensuring feedback is positive and educational.\n",
    "4. Dynamically utilize available tools to extract and analyze key information based on the resume context.\n",
    "5. Continuously update advice with the latest industry trends and job market requirements.\n",
    "**Analysis Framework:**\n",
    "- Personal Information: Name, Contact, LinkedIn Profile\n",
    "- Professional Summary: Key achievements and career goals, emphasizing quantifiable outcomes\n",
    "- Work Experience: Roles, responsibilities, and achievements, highlighted with specific metrics\n",
    "- Skills: Technical and soft skills pertinent to the industry\n",
    "- Education: Degrees, certifications, and relevant coursework aligned with role requirements\n",
    "- Additional Sections: Awards, publications, languages, with attention to detail and relevance\n",
    "- Overall Format and Style: Clarity, conciseness, and professionalism consistent with industry standards\n",
    "**Important Guidelines:**\n",
    "- Respond exclusively to queries related to resume analysis and improvement.\n",
    "- For non-relevant questions, politely respond: \"I apologize, but I can only assist with resume analysis and improvement. Please ask me about resume-related queries.\"\n",
    "- Provide specific examples and metrics to illustrate feedback effectively.\n",
    "- Maintain a supportive and constructive tone, fostering improvement and growth.\n",
    "- Encourage the use of industry standards and current job market trends when formulating recommendations.\n",
    "Deliver clear, actionable insights that empower individuals to enhance their resumes for potential employers, adapting to varied professional and industry contexts.\"\"\"\n",
    "model = wrap_gemini(ChatGoogleGenerativeAI(model='gemini-3-pro-preview')) #\n",
    "\n",
    "# Create an agent for resume analysis with the defined system prompt and tools\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        read_resume,\n",
    "        extract_information,\n",
    "        generate_summary,\n",
    "        calculate_experience_years,\n",
    "        match_job_requirements,\n",
    "        suggest_improvements,\n",
    "    ],\n",
    "    middleware=[TodoListMiddleware(),\n",
    "                PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "                PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n",
    "                PIIMiddleware(\"url\", strategy=\"redact\", apply_to_input=True)],  # Middleware can be customized if needed\n",
    "    system_prompt=system_prompt  # Use the custom system prompt\n",
    ")\n",
    "\n",
    "# Example usage: Analyze a resume and generate a summary report\n",
    "resume_file_path = \"./data/MansoorAliSyed.pdf\"\n",
    "config = {'configurable': {'thread_id': 'resume_session_1'}}\n",
    "# for chunk in agent.stream({'messages':[f\"Analyze resume from file: {resume_file_path}\"]}, stream_mode='values', config=config):\n",
    "#     print(chunk)\n",
    "#     print(\"------\\n\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:06:24,112 - WARNING - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "C:\\Users\\TIGER\\AppData\\Local\\Temp\\ipykernel_54072\\703105020.py:548: LangSmithBetaWarning: Function wrap_gemini is in beta.\n",
      "  model = wrap_gemini(ChatGoogleGenerativeAI(model='gemini-3-pro-preview')) #\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T18:07:46.454183200Z",
     "start_time": "2026-01-02T18:06:25.407084600Z"
    }
   },
   "cell_type": "code",
   "source": "response = agent.invoke({'messages':[f\"Analyze resume from file: {resume_file_path}\"]})",
   "id": "2806db2f33e7215f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:06:30,229 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-02 13:06:32,588 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-02 13:06:32,678 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-02 13:06:32,741 - INFO - Going to convert document batch...\n",
      "2026-01-02 13:06:32,742 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-02 13:06:32,783 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-02 13:06:32,787 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-02 13:06:32,825 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-02 13:06:32,833 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading resume from: ./data/MansoorAliSyed.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:06:33,157 - INFO - Accelerator device: 'cpu'\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,179 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001B[0m\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,196 [RapidOCR] download_file.py:60: File exists and is valid: F:\\Projects\\Multi-Agent-Deep-RAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001B[0m\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,197 [RapidOCR] main.py:53: Using F:\\Projects\\Multi-Agent-Deep-RAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001B[0m\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,303 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001B[0m\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,325 [RapidOCR] download_file.py:60: File exists and is valid: F:\\Projects\\Multi-Agent-Deep-RAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001B[0m\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,326 [RapidOCR] main.py:53: Using F:\\Projects\\Multi-Agent-Deep-RAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001B[0m\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,382 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001B[0m\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,460 [RapidOCR] download_file.py:60: File exists and is valid: F:\\Projects\\Multi-Agent-Deep-RAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001B[0m\n",
      "\u001B[32m[INFO] 2026-01-02 13:06:33,464 [RapidOCR] main.py:53: Using F:\\Projects\\Multi-Agent-Deep-RAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001B[0m\n",
      "2026-01-02 13:06:33,680 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-02 13:06:33,756 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-02 13:06:33,768 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-02 13:06:33,786 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-02 13:06:34,707 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-02 13:06:34,711 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-02 13:06:34,804 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-02 13:06:35,421 - INFO - Processing document MansoorAliSyed.pdf\n",
      "2026-01-02 13:06:45,149 - INFO - Finished converting document MansoorAliSyed.pdf in 12.47 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read resume. Content length: 9643 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:07:05,795 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting information from resume\n",
      "Successfully extracted information. Name: ## MANSOOR ALI SYED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:07:09,979 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-02 13:07:12,936 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating years of experience\n",
      "Calculated 0 years of experience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:07:18,883 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-02 13:07:22,484 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summary report\n",
      "Summary report generated successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:07:25,458 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-02 13:07:28,843 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating improvement suggestions\n",
      "Generated 16 improvement suggestions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:07:34,136 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-02 13:07:46,377 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T18:07:46.584029200Z",
     "start_time": "2026-01-02T18:07:46.486717800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response['messages'][-1].text))"
   ],
   "id": "7b588fd0106d08b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Based on the analysis of the resume for **Mansoor Ali Syed**, here is a comprehensive report and suggestions for improvement.\n\n### **Resume Analysis Report**\n\n**1. Personal Information**\n*   **Name:** Mansoor Ali Syed\n*   **Role:** Gen AI Leader | AI/ML Architect\n*   **Contact:** +13473456387 | mansoor.ali@live.com | [LinkedIn Profile](https://www.linkedin.com/in/manxp)\n*   **Location:** New York, NY\n\n**2. Professional Summary**\n*   **Overview:** A highly experienced professional with over **20 years** in software engineering leadership. The summary strongly positions the candidate as a specialist in Generative AI, AI/ML Architecture, and LLMOps.\n*   **Strengths:** Effectively highlights key technologies (Llama, Mistral, LangChain, Azure ML) and high-level responsibilities (RAG pipelines, multi-agent systems, team leadership).\n\n**3. Work Experience**\n*   **Total Experience:** ~20+ Years\n*   **Current Role:** AI ML Lead/Gen AI Architect at NYC School Construction Authority (July 2022 ‚Äì Present).\n*   **Previous Roles:**\n    *   Solution Architect/Technical Lead at NYC School Construction Authority (2014 ‚Äì 2022).\n    *   Sr. Software Developer III at ICE Mortgage Technology (2012 ‚Äì 2014).\n    *   Sr. .NET Consultant at EagleView Technologies (2011 ‚Äì 2012).\n    *   Various engineering roles (2002 ‚Äì 2011).\n*   **Key Achievements:**\n    *   Architected end-to-end LLMOps pipelines and secure agentic frameworks.\n    *   Reduced manual reporting time by **60%** through a centralized \"single source of truth\" system.\n    *   Managed Agile development for over 60 sprints and mentored developers.\n    *   Optimized SQL procedures reducing runtime by **60%**.\n\n**4. Skills**\n*   **Comprehensive Coverage:** Excellent breakdown into categories: Programming Languages (Python, C#, SQL), Cloud AI Platforms (Azure, Nvidia NIM), Generative AI (LangChain, Semantic Kernel, GPT-4), ML Frameworks (PyTorch, MLflow), and Cloud Native Tools (Docker, Kubernetes).\n\n**5. Education & Certifications**\n*   **Education:**\n    *   MS in Software Engineering, Sir Syed University of Engineering and Technology.\n    *   BS in Computer Science, Sir Syed University of Engineering and Technology.\n*   **Certifications:** Extensive list including NVIDIA Certified Professional (Agentic AI), Google Cloud Generative AI Leader, and Microsoft Azure certifications (AZ-400, MCSA).\n\n---\n\n### **Suggestions for Improvement**\n\nWhile the resume is very strong technically, here are a few refinements to make it even better:\n\n**1. Formatting and Consistency**\n*   **Date Formats:** Ensure date formats are consistent. Some entries use \"MM/YYYY\" while the summary mentions \"over 20 years\".\n*   **Visual Elements:** The \"Badge Wallet\" section mentions an `<!-- image -->`. Ensure that if this is a text-based resume (for ATS), the image placeholder is removed or replaced with a text list of badges if they are different from the certifications.\n\n**2. Impact & Metrics**\n*   **Quantify Early Roles:** While recent roles have excellent metrics (e.g., \"reduced query runtime by 60%\"), the earliest \"Prominent Work (2002-2011)\" section is a bulleted list without specific company names or dates for each project. If space permits, breaking this down into specific roles with 1-2 key achievements each would add more weight to that decade of experience.\n\n**3. Summary Optimization**\n*   **Conciseness:** The professional summary is quite dense. Breaking it into 2-3 shorter paragraphs or using bold text for key terms (e.g., **Gen AI Leader**, **LLMOps**) can improve readability for recruiters scanning quickly.\n\n**4. ATS Optimization**\n*   **Keyword Density:** The resume is already rich in keywords. However, ensure that the specific job titles you are targeting (e.g., \"VP of AI\", \"Head of Machine Learning\") appear explicitly in the summary or headline if they differ from your current title.\n\n**5. Grammar and Phrasing**\n*   **Minor Edits:**\n    *   \"City Government organization specializing and manages...\" -> \"City Government organization specializing **in** and **managing**...\"\n    *   \"C 14 above)\" -> Likely meant \"C++ (14 and above)\".\n\n**Overall Verdict:**\nThis is a **high-quality, senior-level resume** that effectively showcases deep technical expertise and leadership. The candidate clearly demonstrates a transition from traditional software engineering/architecture to cutting-edge AI/ML leadership."
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
